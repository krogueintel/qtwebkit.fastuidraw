Building:
  Tools/Scripts/build-webkit --qt --release --cmakeargs="-DENABLE_MINIBROWSER=ON"
  Tools/Scripts/build-webkit --qt --debug --cmakeargs="-DENABLE_MINIBROWSER=ON"
  
  Disable Features:
    --no-accelerated-2d-canvas --no-video --no-3d-rendering --no-webgl --no-video-track
  

Qt WebKit: rendering.
  Entry point to drawing with QPainter is QWebFrameAdapter::renderRelativeCoords()
  in Source/WebKit/qt/WebCoreSupport/QWebFrameAdapter.cpp. Full stack:

  QWebView::paint() --> QWebFrame::render() --> QWebFrameAdapter::renderRelativeCoords()

  Basic plan:
    1. WebCore infrastucture: namespaced functions to initialize FastUIDraw
       resources (atlases, caches) and OpenGL function setup for
       fastuidraw::gl::gl_binding. (done)
    2. Change QWebView to derived from QOpenGLWidget where QOpenGLContext
       of it is GL 4.5 core profile. (done)
    3. Construct fastuidraw::Painter in QWebView. (done and verified to
       draw).
    4. Modify QtTestBrowser to allow selecting FastUIDraw or QPainter to
       draw. (done for WebViewTraditional and additional stuff to prevent
       re-creation of FastUIDraw resources).
    5. Broad strokes:
       a. change PlatformGraphicsContext from QPainter to something that
          has both a fastuidraw::Painter and a QPainter. (done)
          i. A total of 32 files were touched:
             - 19 in WebCore
             -  7 in WebKit
             -  6 in WebKit2
          ii. The changes in WebKit2 we can ignore, since we are just
              doing the WebKit API; However, we need to also pay careful
              attention to GraphicsContext::isAccelerated() along with
              all the various Image classes in WebKit to make sure
              we render all content with one renderer or the other.
              How "accellerated 2d" (i.e. ACCELERATED_2D_CANVAS)
              interacts needs to be understood as well; that macro
              appears in (thankfully) only 19 files.
          iii. GraphicsContext draw-state:
              - stroke thickness (m_state.strokeThickness)
              - stroke style (m_state.strokeStyle)
              - stroke dash-pattern (m_state.strokePattern)
              - stroke color (m_state.strokeColor)
              - stroke gradient (m_state.strokeGradient)
              - stroke pattern (m_state.strokePattern)
              - fill rule (m_state.fillRule)
              - fill color (m_state.fillColor)
              - fill pattern (m_state.fillPattern)
              - fill gradient (m_state.fillGradient)
          iv. drawing methods (a Pattern in WebCore is an image with repeat arguments and a transformation attached)
              - drawRect: fill a rectangle and stroke its border with the given thickness (instead of state's stroke width)
              - drawLine: stroke a line
              - drawEllipse: fill and stroke an ellipse
              - fillPath: fill a path (do NOT stroke it)
              - strokePath: stroke a path
              - fillElipse: fill an elipse (do NOT stroke it)
              - strokeElipse: stroke an elipse
              - fillRect: fill a rect (do NOT stroke it)
              - fillRoundedRect: fill a rounded rect (do NOT stroke it)
              - clearRect (???)
              - strokeRect: onyl stroke a rect
              - drawImage: draw a rect where brush is an image
              - drawPattern
           v. Image represents a static image, but appears to be a virtual base class
              - The derived types appear to be
                  * BitmapImage wraps over an array of FrameData which is rougly just a wrapper over
                    NativeImagePtr; we need to add to FrameData the necessary fastuidraw field.
                    Not clear when the data should be generated though.
                  * GeneratedImage which is also a pure-virtual base-class
                       ^ GradientImage is for caching a gradient render; 
                       ^ NamedImageGeneratedImage, appears to be used for theme rendering; likely not active (?)
                       ^ BitmapImage
                  * SVGImage is for caching renders of SVG when it is rendered in drawPattern.
                  * StillImage is used for presenting contents of off-screen renders.
              - NativeImagePtr is likely the type to pass around for drawing images;
                for most platforms PassNativeImagePtr is an alias to NativeImagePtr
                (including Qt). To get the PassNativeImagePtr for an image, the
                virtual method Image::nativeImageForCurrentFrame() is to be overridden
              - Rendering to offscreen has additional class, ImageBuffer and ImageBufferData
                that adds more layers of C++ code.
              - (Mostly Done) Plan: add to Image class an interface function readyFastUIDrawBrush()
                whose job is to ready a fastuidraw::PainterBrush to brush with the image.
              - Plan: ImageBuffer/ImageBufferData change createCompatibleBuffer() to examine the
                backend of the passed context and use that method as much as possible. For when
                a context is not available use the page settings to decide.
              - SVGImage is going to be a pain; we can in theory use the ImageBuffer interface, but
                that really sucks because it looks like it regenerates the image every time drawPattern
                is hit.
                  
       b. text
         i. modify GlyphBuffer and/or TextRun to have a fastuidraw structs for text.
         ii. the actual drawing methods in a backend are located in FontCascade
         iii. Use (just created) FastUIDraw class fastuidraw::GlyphRun because
              WebKit works with ranges of text and does its own culling.
         iv. GlyphSelection is done at GlyphPageTreeNodeQt, GlyphPage::fill().
             the *hard* nasty part is that a fixed GlyphPage only has one store
             for what glyph codes to use. In addition, the glyph code is stored
             as a WebCore::Glyph which is just a typedef to unsigned short (16-bit).
             The main issues we have to tackle are:
               - what happens if glype code is greater than 0xFFFF ? This is
                 not likely since that means a really, really big font.
               - What happens if the font chosen by qt is different than the
                 font chosen by FastUIDraw? 
       c. GraphicsContext itself has state for how to stroke and filling
          where each has a color (WebCore::Color), gradient (WebCore::Gradient)
          and pattern (WebCore::Pattern); hopefully we can emulate Pattern
          with fastuidraw::PainterBrush. These classes have the methods
          to fill and draw that take a GraphicsContext. Also related,
          NativeImagePtr will need to change to a pointer that has
          a "something" that points to both a QPixmap and/or a
          fastuidraw::Image as well.
       d. Compositing Layers.
          i. WebKit/WebCore has a compositing engine embodied by the classes
             GraphicsLayerClient and GraphicsLayer. The Qt implementation of
             GraphicsLayerClient is TextureMapperLayerClientQt which is instanced
             by ChromeClientQt::attachRootGraphicsLayer().
          ii. It might be best to disable a bunch of stuff to just avoid it,
              the file Tools/Scripts/webkitperl/FeatureList.pm lists the features,
              and likely the easies way is to disable:
                 - accelerated-2d-canvas
                 - 3d-rendering
                 - webgl
       e. ImageBuffer. Webkit has a class for offscreen rendering, ImageBuffer
          (file Source/WebCore/graphics/ImageBuffer), the backing store is
          platform specific stuff via the class ImageBufferData (with a Qt variant).
          We will need a FastUIDraw variant, the methods to really handle
          are ImageBuffer::draw() and ImageBuffer::drawPattern(). Lots of plumbing
          to walk through.
